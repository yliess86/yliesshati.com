---
title: "Text-Driven Mouth Animation for Human Computer Interaction with Personal Assistant"
date: "20/01/2023"
cover: "/images/publications/tdma.webp"
min: 1
type: publication
tags:
    - deep-learning
    - python
    - opengl
    - pytorch
    - procedural
    - text-to-speech
    - speech-to-animation
abstract: |
    This paper proposes a new neural architecture for text-driven 3D mouth animations for personal assistants
    to improve the realism and naturalness of the interactions. The study shows that such visual feedback
    improves users comfort for 78% of the candidates significantly while slightly improving their time perception.
public: true
---

Personal assistants are becoming more pervasive in our environments but still do not provide natural interactions.
Their lack of realism in term of expressiveness and their lack of visual feedback can create frustrating experiences
and make users lose patience. In this sense, we propose an end-to-end trainable neural architecture for text-driven
3D mouth animations. Previous works showed such architectures provide better realism and could open the door for
integrated affective Human Computer Interface (HCI). Our study shows that such visual feedback improves usersâ€™ comfort
for 78% of the candidates significantly while slightly improving their time perception.

*Click on the paper image to read the paper.*

[![screenshot](/images/blog/tdma_screenshot.webp)](https://doi.org/10.21785/icad2019.032)