- title: "StencilTorch: an Iterative and User-Guided Framework for Anime Lineart Colorization"
  conference: Image and Vision Computing New Zealand (IVCNZ)
  year: 2022
  authors:
    - name: Yliess
      surname: Hati
    - name: Vincent
      surname: Thevenin
    - name: Florent
      surname: Nolot
    - name: Francis
      surname: Rousseaux
    - name: Clement
      surname: Duhart
  abstract: |
    This paper presents StencilTorch, a new approach to the task of automatic lineart colorization in computer vision.
    It is an interactive and user-guided framework that generates illustrations from a given lineart, color hints, and
    a mask, allowing for iterative workflows where the output of the first pass becomes the input of a second. This
    approach improves upon previous methods in both objective and subjective evaluations.

  doi: coming soon
  cover: /images/publications/stenciltorch.webp
- title: "PaintsTorch: a User-Guided Anime Line Art Colorization Tool with Double Generator Conditional Adversarial Network"
  conference: European Conference on Visual Media Production (CVMP)
  year: 2019
  authors:
    - name: Yliess
      surname: Hati
    - name: Gregor
      surname: Jouet
    - name: Francis
      surname: Rousseaux
    - name: Clement
      surname: Duhart
  abstract: |
    This paper presents a new approach for user guided-colorization of line arts in computer vision. The current state
    of the art uses GANs to generate realistic and precise colorization, but relies on randomly sampled pixels as color
    hints for training. This approach aims to improve upon this by introducing a stroke simulation based approach for
    hint generation, making the model more robust to messy inputs. We also propose a new cleaner dataset, and explore
    the use of a double generator GAN to improve visual fidelity.
  doi: 10.1145/3359998.3369401
  cover: /images/publications/paintstorch.webp
- title: "Text-Driven Mouth Animation for Human Computer Interaction with Personal Assistant"
  conference: International Conference on Auditory Display (ICAD)
  year: 2019
  authors:
    - name: Yliess
      surname: Hati
    - name: Francis
      surname: Rousseaux
    - name: Clement
      surname: Duhart
  abstract: |
    This paper proposes a new neural architecture for text-driven 3D mouth animations for personal assistants to improve
    the realism and naturalness of the interactions. The study shows that such visual feedback improves users comfort for 78%
    of the candidates significantly while slightly improving their time perception.
  doi: 10.21785/icad2019.032
  cover: /images/publications/tdma.webp